<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>server API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>server</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import copy
from collections import OrderedDict

import matplotlib.pyplot as plt
import numpy as np
import torch
from PIL import Image

import datasets.ss_transforms as sstr
from utils.utils import get_save_string


class Server:
    &#34;&#34;&#34;
    A class representing the Server for both centralized mode and distributed mode without FDA.

    The Server is responsible for coordinating the training process of the system. It handles
    the client-server framework.

    Args:
        args: An object containing the arguments and configuration for the FDA server.
        train_clients: A list of training clients.
        test_clients: A list of test clients.
        model: The initial source model.
        metrics: A dictionary containing evaluation metrics.
        valid (bool): Whether to include validation during training. Default is False.
        valid_clients: A list of validation clients. Required if `valid` is True. Default is None.
    &#34;&#34;&#34;
    def __init__(self, args, train_clients, test_clients, model, metrics, valid=False, valid_clients=None):
        self.args = args
        self.train_clients = train_clients
        self.test_clients = test_clients
        self.validation_clients = valid_clients
        self.model = model
        self.metrics = metrics
        self.activate_val = valid
        self.model_params_dict = copy.deepcopy(self.model.state_dict())

    def select_clients(self, seed=None):
        &#34;&#34;&#34;
        Selects a subset of clients for a training round.

        Args:
            seed (int): Random seed for client selection. Default is None.

        Returns:
            numpy.ndarray: An array of selected clients for the training round.
        &#34;&#34;&#34;
        num_clients = min(self.args.clients_per_round, len(self.train_clients))
        if seed:
            np.random.seed(seed)
        else:
            np.random.seed(self.args.seed)
        return np.random.choice(self.train_clients, num_clients, replace=False)

    def train_round(self, clients):
        &#34;&#34;&#34;
            This method trains the model with the dataset of the clients. It handles the training at single round level
            Args:
                `clients`: list of all the clients to train
            Returns:
                list[tuple]: [(len_dataset, state_dictionary)]. Model updates gathered from the client to be aggregated.
        &#34;&#34;&#34;
        updates = []

        for i, c in enumerate(clients):
            print(f&#34;Client: {c.name} turn: Num. of samples: {len(c.dataset)}, ({i+1}/{len(clients)})&#34;)

            # Update parameters of the client model
            c.model.load_state_dict(self.model_params_dict)

            if self.args.val:
                self.metrics[&#34;eval_train&#34;].reset()
                update = c.train(self.metrics[&#34;eval_train&#34;], [self.test_clients[0].test_loader, self.test_clients[1].test_loader]) 
            else:
                update = c.train()    

            updates.append(update)
            
        return updates

    def aggregate(self, updates):
        &#34;&#34;&#34;
        Aggregates the model updates received from the clients using FedAvg.

        Args:
            `updates`: Model updates received from the clients. List of tuples.

        Returns:
            OrderedDict: Aggregated model parameters.
        &#34;&#34;&#34;
        total_weight = 0.
        base = OrderedDict()

        # Numerator of weighted average
        for (client_samples, client_model) in updates:
            total_weight += client_samples
            for key, value in client_model.items():
                if key in base:
                    base[key] += client_samples * value.type(torch.FloatTensor)
                else:
                    base[key] = client_samples * value.type(torch.FloatTensor)

        averaged_sol_n = copy.deepcopy(self.model_params_dict)

        # Denominator of weighted average
        for key, value in base.items():
            if total_weight != 0:
                averaged_sol_n[key] = value.to(&#39;cuda&#39;) / total_weight

        # Return weighted average
        return averaged_sol_n

    def train(self):
        &#34;&#34;&#34;
        This method orchestrates the training the evals and tests at rounds level
        &#34;&#34;&#34;

        retrain_error=False
        num_rounds = self.args.num_rounds
        if self.args.centr:
            num_rounds = 1
        
        if self.args.load or self.args.resume or self.args.load_from:
            # If specified a custom name for the saved model load the path
            if self.args.load_from:
                pth = self.args.load_from
            else:
                pth = f&#34;models/checkpoints/{get_save_string(self.args, False)}_checkpoint.pth&#34; if self.args.chp else f&#34;models/{get_save_string(self.args, False)}_best_model.pth&#34;
            try:
                saved_params = torch.load(pth)
                self.model_params_dict = saved_params
                self.model.load_state_dict(saved_params)
                self.model.eval()
                to_print = &#34; from checkpoints.&#34; if self.args.chp else &#34;.&#34;
                print(f&#34;Model loaded{to_print}&#34;)
            except:
                print(&#34;The checkpoint for this model does not exist. The model will be retrained.&#34;)
                retrain_error=True
            
        if (not self.args.load and not self.args.load_from) or self.args.resume or retrain_error:
            for r in range(num_rounds):
                print(&#34;------------------&#34;)
                print(f&#34;Round {r+1}/{num_rounds} started.&#34;)
                print(&#34;------------------&#34;)

                # Select random subset of clients
                chosen_clients = self.select_clients(seed=r)
                
                # Train a round
                updates = self.train_round(chosen_clients)

                # Aggregate the parameters
                self.model_params_dict = self.aggregate(updates)
                self.model.load_state_dict(self.model_params_dict) 
            
            if self.args.save:
                print(&#34;Saving model...&#34;)
                torch.save(self.model_params_dict, f&#39;models/{get_save_string(self.args, False)}_best_model.pth&#39;)

        if self.args.plot == False:
            self.eval_train()
            if self.validation_clients:
                self.eval_validation()
            self.test()

    def eval_train(self):
        &#34;&#34;&#34;
        This method handles the evaluation on the train clients
        &#34;&#34;&#34;
        print(&#34;------------------------------------&#34;)
        print(f&#34;Evaluation of the trainset started.&#34;)
        print(&#34;------------------------------------&#34;) 

        self.metrics[&#34;eval_train&#34;].reset()

        for c in self.train_clients:
            c.model.load_state_dict((copy.deepcopy(self.model_params_dict)))
            c.test(self.metrics[&#34;eval_train&#34;])

        res=self.metrics[&#34;eval_train&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

    def eval_validation(self):
        &#34;&#34;&#34;
        This method handles the evaluation on the validation client(s)
        &#34;&#34;&#34;
        print(&#34;------------------------------------&#34;)
        print(f&#34;Evaluation of the validation set started.&#34;)
        print(&#34;------------------------------------&#34;) 

        self.metrics[&#34;eval_train&#34;].reset()
        self.validation_clients[0].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        self.validation_clients[0].test(self.metrics[&#34;eval_train&#34;])
    
        res=self.metrics[&#34;eval_train&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)
        return res[&#34;Mean IoU&#34;]

    def test(self):
        &#34;&#34;&#34;
            This method handles the test on the test clients
        &#34;&#34;&#34;
        print(&#34;------------------------------------&#34;)
        print(f&#34;Test on SAME DOMAIN DATA started.&#34;)
        print(&#34;------------------------------------&#34;)

        self.test_clients[0].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        self.test_clients[0].test(self.metrics[&#34;test_same_dom&#34;])

        res=self.metrics[&#34;test_same_dom&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

        print(&#34;------------------------------------&#34;)
        print(f&#34;Test on DIFFERENT DOMAIN DATA started.&#34;)
        print(&#34;------------------------------------&#34;)

        self.test_clients[1].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        self.test_clients[1].test(self.metrics[&#34;test_diff_dom&#34;])

        res=self.metrics[&#34;test_diff_dom&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

    def predict(self, image_path):
        &#34;&#34;&#34;
        Handles the the prediction. Outputs an image in the root directory.

        Args: 
            `image_path`: path to the image to predict.
        &#34;&#34;&#34;
        def get_outputs(images, labels=None, test=False):
            if self.args.model == &#39;deeplabv3_mobilenetv2&#39;:
                return self.model(images)[&#39;out&#39;]
            if self.args.model in [&#39;resnet18&#39;,]:
                return self.model(images)
            if self.args.model == &#39;segformer&#39;:
                logits = self.model(images).logits
                outputs = torch.nn.functional.interpolate(
                        logits, 
                        size=images.shape[-2:], 
                        mode=&#34;bilinear&#34;, 
                        align_corners=False
                )
                return outputs
            if self.args.model == &#39;bisenetv2&#39;:
                outputs = self.model(images, test=test)
                return outputs
        # Load and preprocess the input image
        input_image = Image.open(image_path)

        # Apply necessary transformations
        transforms= sstr.Compose([
            sstr.ToTensor(),
            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        input_tensor = transforms(input_image).unsqueeze(0)  # Add batch dimension
        input_tensor = input_tensor.cuda()
        self.model.eval()

        # Perform inference
        with torch.no_grad():
            output = get_outputs(input_tensor, test=True)  # Get the output logits
        output = output.squeeze(0).cpu().numpy()
    
        normalized_output = (output - output.min()) / (output.max() - output.min())

        predicted_labels = np.argmax(normalized_output, axis=0)

        colormap = plt.cm.get_cmap(&#39;tab20&#39;, predicted_labels.max() + 1)

        # Create the predicted image with colors
        predicted_image = Image.fromarray((colormap(predicted_labels) * 255).astype(np.uint8))
        
        # Save the predicted image
        if self.args.dataset != &#34;loveda&#34;:
            class_names = [&#34;road&#34;, &#34;sidewalk&#34;, &#34;building&#34;, &#34;wall&#34;, &#34;fence&#34;, &#34;pole&#34;, &#34;traffic light&#34;, &#34;traffic sign&#34;, &#34;vegatation&#34;, &#34;terrain&#34;, &#34;sky&#34;, &#34;person&#34;, &#34;rider&#34;, &#34;car&#34;, &#34;motorcycle&#34;, &#34;bicycle&#34;]
        else:
            class_names = [&#34;DC&#34;, &#34;background&#34;, &#34;building&#34;, &#34;road&#34;, &#34;water&#34;, &#34;barren&#34;, &#34;forest&#34;, &#34;agriculture&#34;]

        # Create a legend
        legend_elements = [plt.Rectangle((0, 0), 1, 1, color=colormap(i)) for i in range(len(class_names))]

        # Create a figure and axes
        _, ax = plt.subplots()

        # Display the predicted image
        ax.imshow(np.array(input_image))

        if self.args.dataset == &#34;loveda&#34;:
            ax.imshow(predicted_image, alpha=0.4)
        else:  
            ax.imshow(predicted_image, alpha=0.7)
        ax.axis(&#39;off&#39;)

        # Create the legend outside the image
        legend = ax.legend(legend_elements, class_names, loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
        # Adjust the positioning and appearance of the legend
        legend.set_title(&#39;Legend&#39;)
        frame = legend.get_frame()
        frame.set_edgecolor(&#39;black&#39;)
        frame.set_facecolor(&#39;white&#39;)

        # Save the figure
        plt.savefig(&#39;image_fin.png&#39;, bbox_inches=&#39;tight&#39;, dpi=300)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="server.Server"><code class="flex name class">
<span>class <span class="ident">Server</span></span>
<span>(</span><span>args, train_clients, test_clients, model, metrics, valid=False, valid_clients=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A class representing the Server for both centralized mode and distributed mode without FDA.</p>
<p>The Server is responsible for coordinating the training process of the system. It handles
the client-server framework.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>args</code></strong></dt>
<dd>An object containing the arguments and configuration for the FDA server.</dd>
<dt><strong><code>train_clients</code></strong></dt>
<dd>A list of training clients.</dd>
<dt><strong><code>test_clients</code></strong></dt>
<dd>A list of test clients.</dd>
<dt><strong><code>model</code></strong></dt>
<dd>The initial source model.</dd>
<dt><strong><code>metrics</code></strong></dt>
<dd>A dictionary containing evaluation metrics.</dd>
<dt><strong><code>valid</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to include validation during training. Default is False.</dd>
<dt><strong><code>valid_clients</code></strong></dt>
<dd>A list of validation clients. Required if <code>valid</code> is True. Default is None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Server:
    &#34;&#34;&#34;
    A class representing the Server for both centralized mode and distributed mode without FDA.

    The Server is responsible for coordinating the training process of the system. It handles
    the client-server framework.

    Args:
        args: An object containing the arguments and configuration for the FDA server.
        train_clients: A list of training clients.
        test_clients: A list of test clients.
        model: The initial source model.
        metrics: A dictionary containing evaluation metrics.
        valid (bool): Whether to include validation during training. Default is False.
        valid_clients: A list of validation clients. Required if `valid` is True. Default is None.
    &#34;&#34;&#34;
    def __init__(self, args, train_clients, test_clients, model, metrics, valid=False, valid_clients=None):
        self.args = args
        self.train_clients = train_clients
        self.test_clients = test_clients
        self.validation_clients = valid_clients
        self.model = model
        self.metrics = metrics
        self.activate_val = valid
        self.model_params_dict = copy.deepcopy(self.model.state_dict())

    def select_clients(self, seed=None):
        &#34;&#34;&#34;
        Selects a subset of clients for a training round.

        Args:
            seed (int): Random seed for client selection. Default is None.

        Returns:
            numpy.ndarray: An array of selected clients for the training round.
        &#34;&#34;&#34;
        num_clients = min(self.args.clients_per_round, len(self.train_clients))
        if seed:
            np.random.seed(seed)
        else:
            np.random.seed(self.args.seed)
        return np.random.choice(self.train_clients, num_clients, replace=False)

    def train_round(self, clients):
        &#34;&#34;&#34;
            This method trains the model with the dataset of the clients. It handles the training at single round level
            Args:
                `clients`: list of all the clients to train
            Returns:
                list[tuple]: [(len_dataset, state_dictionary)]. Model updates gathered from the client to be aggregated.
        &#34;&#34;&#34;
        updates = []

        for i, c in enumerate(clients):
            print(f&#34;Client: {c.name} turn: Num. of samples: {len(c.dataset)}, ({i+1}/{len(clients)})&#34;)

            # Update parameters of the client model
            c.model.load_state_dict(self.model_params_dict)

            if self.args.val:
                self.metrics[&#34;eval_train&#34;].reset()
                update = c.train(self.metrics[&#34;eval_train&#34;], [self.test_clients[0].test_loader, self.test_clients[1].test_loader]) 
            else:
                update = c.train()    

            updates.append(update)
            
        return updates

    def aggregate(self, updates):
        &#34;&#34;&#34;
        Aggregates the model updates received from the clients using FedAvg.

        Args:
            `updates`: Model updates received from the clients. List of tuples.

        Returns:
            OrderedDict: Aggregated model parameters.
        &#34;&#34;&#34;
        total_weight = 0.
        base = OrderedDict()

        # Numerator of weighted average
        for (client_samples, client_model) in updates:
            total_weight += client_samples
            for key, value in client_model.items():
                if key in base:
                    base[key] += client_samples * value.type(torch.FloatTensor)
                else:
                    base[key] = client_samples * value.type(torch.FloatTensor)

        averaged_sol_n = copy.deepcopy(self.model_params_dict)

        # Denominator of weighted average
        for key, value in base.items():
            if total_weight != 0:
                averaged_sol_n[key] = value.to(&#39;cuda&#39;) / total_weight

        # Return weighted average
        return averaged_sol_n

    def train(self):
        &#34;&#34;&#34;
        This method orchestrates the training the evals and tests at rounds level
        &#34;&#34;&#34;

        retrain_error=False
        num_rounds = self.args.num_rounds
        if self.args.centr:
            num_rounds = 1
        
        if self.args.load or self.args.resume or self.args.load_from:
            # If specified a custom name for the saved model load the path
            if self.args.load_from:
                pth = self.args.load_from
            else:
                pth = f&#34;models/checkpoints/{get_save_string(self.args, False)}_checkpoint.pth&#34; if self.args.chp else f&#34;models/{get_save_string(self.args, False)}_best_model.pth&#34;
            try:
                saved_params = torch.load(pth)
                self.model_params_dict = saved_params
                self.model.load_state_dict(saved_params)
                self.model.eval()
                to_print = &#34; from checkpoints.&#34; if self.args.chp else &#34;.&#34;
                print(f&#34;Model loaded{to_print}&#34;)
            except:
                print(&#34;The checkpoint for this model does not exist. The model will be retrained.&#34;)
                retrain_error=True
            
        if (not self.args.load and not self.args.load_from) or self.args.resume or retrain_error:
            for r in range(num_rounds):
                print(&#34;------------------&#34;)
                print(f&#34;Round {r+1}/{num_rounds} started.&#34;)
                print(&#34;------------------&#34;)

                # Select random subset of clients
                chosen_clients = self.select_clients(seed=r)
                
                # Train a round
                updates = self.train_round(chosen_clients)

                # Aggregate the parameters
                self.model_params_dict = self.aggregate(updates)
                self.model.load_state_dict(self.model_params_dict) 
            
            if self.args.save:
                print(&#34;Saving model...&#34;)
                torch.save(self.model_params_dict, f&#39;models/{get_save_string(self.args, False)}_best_model.pth&#39;)

        if self.args.plot == False:
            self.eval_train()
            if self.validation_clients:
                self.eval_validation()
            self.test()

    def eval_train(self):
        &#34;&#34;&#34;
        This method handles the evaluation on the train clients
        &#34;&#34;&#34;
        print(&#34;------------------------------------&#34;)
        print(f&#34;Evaluation of the trainset started.&#34;)
        print(&#34;------------------------------------&#34;) 

        self.metrics[&#34;eval_train&#34;].reset()

        for c in self.train_clients:
            c.model.load_state_dict((copy.deepcopy(self.model_params_dict)))
            c.test(self.metrics[&#34;eval_train&#34;])

        res=self.metrics[&#34;eval_train&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

    def eval_validation(self):
        &#34;&#34;&#34;
        This method handles the evaluation on the validation client(s)
        &#34;&#34;&#34;
        print(&#34;------------------------------------&#34;)
        print(f&#34;Evaluation of the validation set started.&#34;)
        print(&#34;------------------------------------&#34;) 

        self.metrics[&#34;eval_train&#34;].reset()
        self.validation_clients[0].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        self.validation_clients[0].test(self.metrics[&#34;eval_train&#34;])
    
        res=self.metrics[&#34;eval_train&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)
        return res[&#34;Mean IoU&#34;]

    def test(self):
        &#34;&#34;&#34;
            This method handles the test on the test clients
        &#34;&#34;&#34;
        print(&#34;------------------------------------&#34;)
        print(f&#34;Test on SAME DOMAIN DATA started.&#34;)
        print(&#34;------------------------------------&#34;)

        self.test_clients[0].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        self.test_clients[0].test(self.metrics[&#34;test_same_dom&#34;])

        res=self.metrics[&#34;test_same_dom&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

        print(&#34;------------------------------------&#34;)
        print(f&#34;Test on DIFFERENT DOMAIN DATA started.&#34;)
        print(&#34;------------------------------------&#34;)

        self.test_clients[1].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        self.test_clients[1].test(self.metrics[&#34;test_diff_dom&#34;])

        res=self.metrics[&#34;test_diff_dom&#34;].get_results()
        print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

    def predict(self, image_path):
        &#34;&#34;&#34;
        Handles the the prediction. Outputs an image in the root directory.

        Args: 
            `image_path`: path to the image to predict.
        &#34;&#34;&#34;
        def get_outputs(images, labels=None, test=False):
            if self.args.model == &#39;deeplabv3_mobilenetv2&#39;:
                return self.model(images)[&#39;out&#39;]
            if self.args.model in [&#39;resnet18&#39;,]:
                return self.model(images)
            if self.args.model == &#39;segformer&#39;:
                logits = self.model(images).logits
                outputs = torch.nn.functional.interpolate(
                        logits, 
                        size=images.shape[-2:], 
                        mode=&#34;bilinear&#34;, 
                        align_corners=False
                )
                return outputs
            if self.args.model == &#39;bisenetv2&#39;:
                outputs = self.model(images, test=test)
                return outputs
        # Load and preprocess the input image
        input_image = Image.open(image_path)

        # Apply necessary transformations
        transforms= sstr.Compose([
            sstr.ToTensor(),
            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        input_tensor = transforms(input_image).unsqueeze(0)  # Add batch dimension
        input_tensor = input_tensor.cuda()
        self.model.eval()

        # Perform inference
        with torch.no_grad():
            output = get_outputs(input_tensor, test=True)  # Get the output logits
        output = output.squeeze(0).cpu().numpy()
    
        normalized_output = (output - output.min()) / (output.max() - output.min())

        predicted_labels = np.argmax(normalized_output, axis=0)

        colormap = plt.cm.get_cmap(&#39;tab20&#39;, predicted_labels.max() + 1)

        # Create the predicted image with colors
        predicted_image = Image.fromarray((colormap(predicted_labels) * 255).astype(np.uint8))
        
        # Save the predicted image
        if self.args.dataset != &#34;loveda&#34;:
            class_names = [&#34;road&#34;, &#34;sidewalk&#34;, &#34;building&#34;, &#34;wall&#34;, &#34;fence&#34;, &#34;pole&#34;, &#34;traffic light&#34;, &#34;traffic sign&#34;, &#34;vegatation&#34;, &#34;terrain&#34;, &#34;sky&#34;, &#34;person&#34;, &#34;rider&#34;, &#34;car&#34;, &#34;motorcycle&#34;, &#34;bicycle&#34;]
        else:
            class_names = [&#34;DC&#34;, &#34;background&#34;, &#34;building&#34;, &#34;road&#34;, &#34;water&#34;, &#34;barren&#34;, &#34;forest&#34;, &#34;agriculture&#34;]

        # Create a legend
        legend_elements = [plt.Rectangle((0, 0), 1, 1, color=colormap(i)) for i in range(len(class_names))]

        # Create a figure and axes
        _, ax = plt.subplots()

        # Display the predicted image
        ax.imshow(np.array(input_image))

        if self.args.dataset == &#34;loveda&#34;:
            ax.imshow(predicted_image, alpha=0.4)
        else:  
            ax.imshow(predicted_image, alpha=0.7)
        ax.axis(&#39;off&#39;)

        # Create the legend outside the image
        legend = ax.legend(legend_elements, class_names, loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
        # Adjust the positioning and appearance of the legend
        legend.set_title(&#39;Legend&#39;)
        frame = legend.get_frame()
        frame.set_edgecolor(&#39;black&#39;)
        frame.set_facecolor(&#39;white&#39;)

        # Save the figure
        plt.savefig(&#39;image_fin.png&#39;, bbox_inches=&#39;tight&#39;, dpi=300)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="server.Server.aggregate"><code class="name flex">
<span>def <span class="ident">aggregate</span></span>(<span>self, updates)</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregates the model updates received from the clients using FedAvg.</p>
<h2 id="args">Args</h2>
<p><code>updates</code>: Model updates received from the clients. List of tuples.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>OrderedDict</code></dt>
<dd>Aggregated model parameters.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate(self, updates):
    &#34;&#34;&#34;
    Aggregates the model updates received from the clients using FedAvg.

    Args:
        `updates`: Model updates received from the clients. List of tuples.

    Returns:
        OrderedDict: Aggregated model parameters.
    &#34;&#34;&#34;
    total_weight = 0.
    base = OrderedDict()

    # Numerator of weighted average
    for (client_samples, client_model) in updates:
        total_weight += client_samples
        for key, value in client_model.items():
            if key in base:
                base[key] += client_samples * value.type(torch.FloatTensor)
            else:
                base[key] = client_samples * value.type(torch.FloatTensor)

    averaged_sol_n = copy.deepcopy(self.model_params_dict)

    # Denominator of weighted average
    for key, value in base.items():
        if total_weight != 0:
            averaged_sol_n[key] = value.to(&#39;cuda&#39;) / total_weight

    # Return weighted average
    return averaged_sol_n</code></pre>
</details>
</dd>
<dt id="server.Server.eval_train"><code class="name flex">
<span>def <span class="ident">eval_train</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method handles the evaluation on the train clients</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_train(self):
    &#34;&#34;&#34;
    This method handles the evaluation on the train clients
    &#34;&#34;&#34;
    print(&#34;------------------------------------&#34;)
    print(f&#34;Evaluation of the trainset started.&#34;)
    print(&#34;------------------------------------&#34;) 

    self.metrics[&#34;eval_train&#34;].reset()

    for c in self.train_clients:
        c.model.load_state_dict((copy.deepcopy(self.model_params_dict)))
        c.test(self.metrics[&#34;eval_train&#34;])

    res=self.metrics[&#34;eval_train&#34;].get_results()
    print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)</code></pre>
</details>
</dd>
<dt id="server.Server.eval_validation"><code class="name flex">
<span>def <span class="ident">eval_validation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method handles the evaluation on the validation client(s)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_validation(self):
    &#34;&#34;&#34;
    This method handles the evaluation on the validation client(s)
    &#34;&#34;&#34;
    print(&#34;------------------------------------&#34;)
    print(f&#34;Evaluation of the validation set started.&#34;)
    print(&#34;------------------------------------&#34;) 

    self.metrics[&#34;eval_train&#34;].reset()
    self.validation_clients[0].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
    self.validation_clients[0].test(self.metrics[&#34;eval_train&#34;])

    res=self.metrics[&#34;eval_train&#34;].get_results()
    print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)
    return res[&#34;Mean IoU&#34;]</code></pre>
</details>
</dd>
<dt id="server.Server.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, image_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Handles the the prediction. Outputs an image in the root directory.</p>
<p>Args:
<code>image_path</code>: path to the image to predict.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, image_path):
    &#34;&#34;&#34;
    Handles the the prediction. Outputs an image in the root directory.

    Args: 
        `image_path`: path to the image to predict.
    &#34;&#34;&#34;
    def get_outputs(images, labels=None, test=False):
        if self.args.model == &#39;deeplabv3_mobilenetv2&#39;:
            return self.model(images)[&#39;out&#39;]
        if self.args.model in [&#39;resnet18&#39;,]:
            return self.model(images)
        if self.args.model == &#39;segformer&#39;:
            logits = self.model(images).logits
            outputs = torch.nn.functional.interpolate(
                    logits, 
                    size=images.shape[-2:], 
                    mode=&#34;bilinear&#34;, 
                    align_corners=False
            )
            return outputs
        if self.args.model == &#39;bisenetv2&#39;:
            outputs = self.model(images, test=test)
            return outputs
    # Load and preprocess the input image
    input_image = Image.open(image_path)

    # Apply necessary transformations
    transforms= sstr.Compose([
        sstr.ToTensor(),
        sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    input_tensor = transforms(input_image).unsqueeze(0)  # Add batch dimension
    input_tensor = input_tensor.cuda()
    self.model.eval()

    # Perform inference
    with torch.no_grad():
        output = get_outputs(input_tensor, test=True)  # Get the output logits
    output = output.squeeze(0).cpu().numpy()

    normalized_output = (output - output.min()) / (output.max() - output.min())

    predicted_labels = np.argmax(normalized_output, axis=0)

    colormap = plt.cm.get_cmap(&#39;tab20&#39;, predicted_labels.max() + 1)

    # Create the predicted image with colors
    predicted_image = Image.fromarray((colormap(predicted_labels) * 255).astype(np.uint8))
    
    # Save the predicted image
    if self.args.dataset != &#34;loveda&#34;:
        class_names = [&#34;road&#34;, &#34;sidewalk&#34;, &#34;building&#34;, &#34;wall&#34;, &#34;fence&#34;, &#34;pole&#34;, &#34;traffic light&#34;, &#34;traffic sign&#34;, &#34;vegatation&#34;, &#34;terrain&#34;, &#34;sky&#34;, &#34;person&#34;, &#34;rider&#34;, &#34;car&#34;, &#34;motorcycle&#34;, &#34;bicycle&#34;]
    else:
        class_names = [&#34;DC&#34;, &#34;background&#34;, &#34;building&#34;, &#34;road&#34;, &#34;water&#34;, &#34;barren&#34;, &#34;forest&#34;, &#34;agriculture&#34;]

    # Create a legend
    legend_elements = [plt.Rectangle((0, 0), 1, 1, color=colormap(i)) for i in range(len(class_names))]

    # Create a figure and axes
    _, ax = plt.subplots()

    # Display the predicted image
    ax.imshow(np.array(input_image))

    if self.args.dataset == &#34;loveda&#34;:
        ax.imshow(predicted_image, alpha=0.4)
    else:  
        ax.imshow(predicted_image, alpha=0.7)
    ax.axis(&#39;off&#39;)

    # Create the legend outside the image
    legend = ax.legend(legend_elements, class_names, loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
    # Adjust the positioning and appearance of the legend
    legend.set_title(&#39;Legend&#39;)
    frame = legend.get_frame()
    frame.set_edgecolor(&#39;black&#39;)
    frame.set_facecolor(&#39;white&#39;)

    # Save the figure
    plt.savefig(&#39;image_fin.png&#39;, bbox_inches=&#39;tight&#39;, dpi=300)</code></pre>
</details>
</dd>
<dt id="server.Server.select_clients"><code class="name flex">
<span>def <span class="ident">select_clients</span></span>(<span>self, seed=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Selects a subset of clients for a training round.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code></dt>
<dd>Random seed for client selection. Default is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>An array of selected clients for the training round.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_clients(self, seed=None):
    &#34;&#34;&#34;
    Selects a subset of clients for a training round.

    Args:
        seed (int): Random seed for client selection. Default is None.

    Returns:
        numpy.ndarray: An array of selected clients for the training round.
    &#34;&#34;&#34;
    num_clients = min(self.args.clients_per_round, len(self.train_clients))
    if seed:
        np.random.seed(seed)
    else:
        np.random.seed(self.args.seed)
    return np.random.choice(self.train_clients, num_clients, replace=False)</code></pre>
</details>
</dd>
<dt id="server.Server.test"><code class="name flex">
<span>def <span class="ident">test</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method handles the test on the test clients</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test(self):
    &#34;&#34;&#34;
        This method handles the test on the test clients
    &#34;&#34;&#34;
    print(&#34;------------------------------------&#34;)
    print(f&#34;Test on SAME DOMAIN DATA started.&#34;)
    print(&#34;------------------------------------&#34;)

    self.test_clients[0].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
    self.test_clients[0].test(self.metrics[&#34;test_same_dom&#34;])

    res=self.metrics[&#34;test_same_dom&#34;].get_results()
    print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)

    print(&#34;------------------------------------&#34;)
    print(f&#34;Test on DIFFERENT DOMAIN DATA started.&#34;)
    print(&#34;------------------------------------&#34;)

    self.test_clients[1].model.load_state_dict((copy.deepcopy(self.model_params_dict)))
    self.test_clients[1].test(self.metrics[&#34;test_diff_dom&#34;])

    res=self.metrics[&#34;test_diff_dom&#34;].get_results()
    print(f&#39;Acc: {res[&#34;Overall Acc&#34;]}, Mean IoU: {res[&#34;Mean IoU&#34;]}&#39;)</code></pre>
</details>
</dd>
<dt id="server.Server.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method orchestrates the training the evals and tests at rounds level</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self):
    &#34;&#34;&#34;
    This method orchestrates the training the evals and tests at rounds level
    &#34;&#34;&#34;

    retrain_error=False
    num_rounds = self.args.num_rounds
    if self.args.centr:
        num_rounds = 1
    
    if self.args.load or self.args.resume or self.args.load_from:
        # If specified a custom name for the saved model load the path
        if self.args.load_from:
            pth = self.args.load_from
        else:
            pth = f&#34;models/checkpoints/{get_save_string(self.args, False)}_checkpoint.pth&#34; if self.args.chp else f&#34;models/{get_save_string(self.args, False)}_best_model.pth&#34;
        try:
            saved_params = torch.load(pth)
            self.model_params_dict = saved_params
            self.model.load_state_dict(saved_params)
            self.model.eval()
            to_print = &#34; from checkpoints.&#34; if self.args.chp else &#34;.&#34;
            print(f&#34;Model loaded{to_print}&#34;)
        except:
            print(&#34;The checkpoint for this model does not exist. The model will be retrained.&#34;)
            retrain_error=True
        
    if (not self.args.load and not self.args.load_from) or self.args.resume or retrain_error:
        for r in range(num_rounds):
            print(&#34;------------------&#34;)
            print(f&#34;Round {r+1}/{num_rounds} started.&#34;)
            print(&#34;------------------&#34;)

            # Select random subset of clients
            chosen_clients = self.select_clients(seed=r)
            
            # Train a round
            updates = self.train_round(chosen_clients)

            # Aggregate the parameters
            self.model_params_dict = self.aggregate(updates)
            self.model.load_state_dict(self.model_params_dict) 
        
        if self.args.save:
            print(&#34;Saving model...&#34;)
            torch.save(self.model_params_dict, f&#39;models/{get_save_string(self.args, False)}_best_model.pth&#39;)

    if self.args.plot == False:
        self.eval_train()
        if self.validation_clients:
            self.eval_validation()
        self.test()</code></pre>
</details>
</dd>
<dt id="server.Server.train_round"><code class="name flex">
<span>def <span class="ident">train_round</span></span>(<span>self, clients)</span>
</code></dt>
<dd>
<div class="desc"><p>This method trains the model with the dataset of the clients. It handles the training at single round level</p>
<h2 id="args">Args</h2>
<p><code>clients</code>: list of all the clients to train</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list[tuple]</code></dt>
<dd>[(len_dataset, state_dictionary)]. Model updates gathered from the client to be aggregated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_round(self, clients):
    &#34;&#34;&#34;
        This method trains the model with the dataset of the clients. It handles the training at single round level
        Args:
            `clients`: list of all the clients to train
        Returns:
            list[tuple]: [(len_dataset, state_dictionary)]. Model updates gathered from the client to be aggregated.
    &#34;&#34;&#34;
    updates = []

    for i, c in enumerate(clients):
        print(f&#34;Client: {c.name} turn: Num. of samples: {len(c.dataset)}, ({i+1}/{len(clients)})&#34;)

        # Update parameters of the client model
        c.model.load_state_dict(self.model_params_dict)

        if self.args.val:
            self.metrics[&#34;eval_train&#34;].reset()
            update = c.train(self.metrics[&#34;eval_train&#34;], [self.test_clients[0].test_loader, self.test_clients[1].test_loader]) 
        else:
            update = c.train()    

        updates.append(update)
        
    return updates</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="server.Server" href="#server.Server">Server</a></code></h4>
<ul class="two-column">
<li><code><a title="server.Server.aggregate" href="#server.Server.aggregate">aggregate</a></code></li>
<li><code><a title="server.Server.eval_train" href="#server.Server.eval_train">eval_train</a></code></li>
<li><code><a title="server.Server.eval_validation" href="#server.Server.eval_validation">eval_validation</a></code></li>
<li><code><a title="server.Server.predict" href="#server.Server.predict">predict</a></code></li>
<li><code><a title="server.Server.select_clients" href="#server.Server.select_clients">select_clients</a></code></li>
<li><code><a title="server.Server.test" href="#server.Server.test">test</a></code></li>
<li><code><a title="server.Server.train" href="#server.Server.train">train</a></code></li>
<li><code><a title="server.Server.train_round" href="#server.Server.train_round">train_round</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>